{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that I've put # infront of the fit and predicts of the models and some other functions. The notebook has been created entirely in colab.google.com so some additional lines might not work in this jupyther. Regardless even if those cells are run the history of epochs and MSE would be lost so please first read the notebook and finally do the check with running all cells if you do the check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybN22zoqZhff"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mhzcod-aS66u"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "RDurmwulTOwJ",
    "outputId": "215edc75-2f16-48dc-8cbd-8704b894c41c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "h0O7uJL1PULU",
    "outputId": "4ac2d589-66de-4215-9520-a258a2f189fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Reshape, Dot, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "#from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LxbhLG3Tgu5F"
   },
   "source": [
    "# Deep Neural Book Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xv9rVJpIg5Oz"
   },
   "source": [
    "## Create and optimize a book recommender using deep neural network.\n",
    "\n",
    "Author: Aleksandar Vladimirov\n",
    "\n",
    "14/02/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DD8Th1hyhNu6"
   },
   "source": [
    "Abstract\n",
    "\n",
    "I’ve been interested in how you get suggestions for what to watch, listen and read. Netflix, Youtube, Spotify and well, Goodreads come to mind. And though I’m thinking of a Netflix subscription just out of interest how good can it get for me for real me and became addicted to Spotify and Movielens recommendation engines are quite interesting. This of course begs the question of course is how are you going to experience something new which is quite unlike yourself (and other with similar tastes people) if you’re constantly bombarded with stuff similar to those you’ve already tried. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1D-aFSuLhQXS"
   },
   "source": [
    "## Table of content:\n",
    "\n",
    "1. Introduction\n",
    "2. Load the data\n",
    "3. Let's take a look at our data (EDA)\n",
    "4. Prepare, train and optimize the model\n",
    "5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "faY9NMs8hX6p"
   },
   "source": [
    "##1. Introduction\n",
    "\n",
    "This is my first time working with tensorflow and google.colab so it’s been quite interesting. I’m using colab because my laptop begs for retirement but I won’t let it go (probably how I’m going to be in 40/45 years time :D )\n",
    "\n",
    "Regarding the recommenders there are more example of movie/song recommenders but too few for books, so I decided to go with a recommender for a book.\n",
    "\n",
    "The dataset I'll be using has data for 10000 books and 53424 users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-Thk10FjtWQ"
   },
   "source": [
    "## 2. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLMJHcOQl36C"
   },
   "source": [
    "The data is pulled from the goodreads.com site and description of it can be found here:\n",
    "https://www.kaggle.com/zygmunt/goodbooks-10k\n",
    "Lucky for me there was a new cleaner version of the data and I’m using directly the links from the link provided in the Kaggle, but I will put it here as well.\n",
    "https://github.com/zygmuntz/goodbooks-10k.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aKT48kfegWoK"
   },
   "outputs": [],
   "source": [
    "#So I'm going to load a few datasets and see what is relevant and what is not\n",
    "books_df = pd.read_csv(\"https://github.com/zygmuntz/goodbooks-10k/raw/master/books.csv\")\n",
    "ratings_df = pd.read_csv(\"https://github.com/zygmuntz/goodbooks-10k/raw/master/ratings.csv\")\n",
    "#just in case to_read table\n",
    "to_read_df = pd.read_csv(\"https://github.com/zygmuntz/goodbooks-10k/raw/master/to_read.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "colab_type": "code",
    "id": "55V_k5IAXvOa",
    "outputId": "50329aa3-a24f-4feb-ed19-70c03e242330"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006560</th>\n",
       "      <td>27415</td>\n",
       "      <td>1234</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  book_id  rating\n",
       "2006560    27415     1234       4"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The usual sample to see what columns we have, and their naming.\n",
    "ratings_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "colab_type": "code",
    "id": "4MKek7XDHP4b",
    "outputId": "f82ab856-ab6f-4317-db9f-57685fb9efd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>title</th>\n",
       "      <th>language_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8651</th>\n",
       "      <td>8652</td>\n",
       "      <td>295169</td>\n",
       "      <td>295169</td>\n",
       "      <td>2919537</td>\n",
       "      <td>54</td>\n",
       "      <td>786814179</td>\n",
       "      <td>9.780787e+12</td>\n",
       "      <td>William Nicholson, Peter Sís</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>The Wind Singer</td>\n",
       "      <td>The Wind Singer (Wind on Fire, #1)</td>\n",
       "      <td>eng</td>\n",
       "      <td>3.84</td>\n",
       "      <td>12654</td>\n",
       "      <td>14508</td>\n",
       "      <td>472</td>\n",
       "      <td>341</td>\n",
       "      <td>957</td>\n",
       "      <td>3647</td>\n",
       "      <td>5351</td>\n",
       "      <td>4212</td>\n",
       "      <td>https://images.gr-assets.com/books/1293635554m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1293635554s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>1251</td>\n",
       "      <td>6468666</td>\n",
       "      <td>6468666</td>\n",
       "      <td>6659237</td>\n",
       "      <td>39</td>\n",
       "      <td>1841497126</td>\n",
       "      <td>9.781841e+12</td>\n",
       "      <td>Kelley Armstrong</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>The Reckoning</td>\n",
       "      <td>The Reckoning (Darkest Powers, #3)</td>\n",
       "      <td>en-GB</td>\n",
       "      <td>4.21</td>\n",
       "      <td>92922</td>\n",
       "      <td>96809</td>\n",
       "      <td>3418</td>\n",
       "      <td>1256</td>\n",
       "      <td>3395</td>\n",
       "      <td>15949</td>\n",
       "      <td>29157</td>\n",
       "      <td>47052</td>\n",
       "      <td>https://images.gr-assets.com/books/1327154591m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1327154591s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id  ...                                    small_image_url\n",
       "8651     8652  ...  https://images.gr-assets.com/books/1293635554s...\n",
       "1250     1251  ...  https://images.gr-assets.com/books/1327154591s...\n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The same for books_df. It seems that here we have a lot of columns, but I'm going to leave it for now as all the data I need is in ratings_df.\n",
    "books_df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vS089Rs8lCtW"
   },
   "source": [
    "##3 Let's take a look at our data (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZgYrfme8lRG5"
   },
   "source": [
    "So we need to check the data, like shape, data types, describe it to see anything which needs correcting (though this is cleaner dataset and should be ok). Checking just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VzjaPONckL-N",
    "outputId": "cc8d97b4-9434-422b-bd4a-f4d2cab83f01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5976479, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "owFsG2nvmJHu",
    "outputId": "1b5e16fc-ab2e-4c01-e45c-2a339039ada7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id    int64\n",
       "book_id    int64\n",
       "rating     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "wzWrmqnIwIS_",
    "outputId": "9b99d95d-5e08-4096-a481-500b3f9f2dda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.976479e+06</td>\n",
       "      <td>5.976479e+06</td>\n",
       "      <td>5.976479e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.622446e+04</td>\n",
       "      <td>2.006477e+03</td>\n",
       "      <td>3.919866e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.541323e+04</td>\n",
       "      <td>2.468499e+03</td>\n",
       "      <td>9.910868e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.281300e+04</td>\n",
       "      <td>1.980000e+02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.593800e+04</td>\n",
       "      <td>8.850000e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.950900e+04</td>\n",
       "      <td>2.973000e+03</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.342400e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id       book_id        rating\n",
       "count  5.976479e+06  5.976479e+06  5.976479e+06\n",
       "mean   2.622446e+04  2.006477e+03  3.919866e+00\n",
       "std    1.541323e+04  2.468499e+03  9.910868e-01\n",
       "min    1.000000e+00  1.000000e+00  1.000000e+00\n",
       "25%    1.281300e+04  1.980000e+02  3.000000e+00\n",
       "50%    2.593800e+04  8.850000e+02  4.000000e+00\n",
       "75%    3.950900e+04  2.973000e+03  5.000000e+00\n",
       "max    5.342400e+04  1.000000e+04  5.000000e+00"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ldbtIhYNMUe4",
    "outputId": "997c1293-480b-4624-a9ff-cd6eb3ac1db4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Going to check if the ratings are as described.\n",
    "ratings_df.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "McPQLn89wtaX",
    "outputId": "9a0a22c7-d080-4c90-84e1-47c56bb4a827"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "1     2.078063\n",
       "2     6.011182\n",
       "3    22.938523\n",
       "4    35.790605\n",
       "5    33.181628\n",
       "Name: user_id, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's see the distribution of those ratings from 1 to 5.\n",
    "ratings_df.groupby(\"rating\")[\"user_id\"].count()/ratings_df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zhf9uAgnxja5"
   },
   "source": [
    "So the predominant ratings are high only around 8% are with low (1 or 2 as a rating). Let's check how this looks like visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "colab_type": "code",
    "id": "HOQmY1TeMCKL",
    "outputId": "489cd0d0-5495-4af6-c5c8-b3bb5800ce0a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABFEAAAGMCAYAAAASgT3xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist , bin_edges = np.histogram(ratings_df.rating)\n",
    "bin_edges = np.round(bin_edges , 0)\n",
    "\n",
    "plt.figure(figsize = [18,6])\n",
    "\n",
    "plt.bar(bin_edges[:-1] , hist, width = 0.5, color = \"sandybrown\",)\n",
    "\n",
    "plt.xlim(min(bin_edges) - 0.5 , max(bin_edges) + 0.5)\n",
    "\n",
    "plt.grid(axis=\"y\", alpha=0.75)\n",
    "plt.xlabel(\"Rating\" , fontsize=14)\n",
    "plt.ylabel(\"Count\" , fontsize=14)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.ylabel(\"Count\" , fontsize = 14)\n",
    "plt.title(\"Rating Distribution of Goodreads Books\" , fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJq75o48yF_O"
   },
   "source": [
    "Almost 70% of the ratings are high (4 or 5). This seems logical since usually in order to rate a movie, song or a book you have to respectively watch/listen or read it. Since it might take days to read a book (comparatively more that the 1-2 hours for a movie or a few minutes for a song) it's normal to see only higher ratings for books."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcKlXz4g2MXe"
   },
   "source": [
    "Let's see what's the distribution of rating per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "drimEraU2Prc"
   },
   "outputs": [],
   "source": [
    "rat_pu = ratings_df.groupby(\"user_id\")[\"rating\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "colab_type": "code",
    "id": "6U5hvZ_p7ok-",
    "outputId": "58d32640-cc7b-44ff-b1db-862de5102ac3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDYAAAGMCAYAAAAhuiL4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = [18,6])\n",
    "plt.hist(rat_pu, bins = 200, color = \"sandybrown\")\n",
    "\n",
    "plt.grid(axis=\"y\", alpha=0.75)\n",
    "plt.xlabel(\"Ratings per user\" , fontsize=14)\n",
    "plt.ylabel(\"Number of users\" , fontsize=14)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.ylabel(\"Number of users\" , fontsize = 14)\n",
    "plt.title(\"Rating Distribution of Goodreads Books\" , fontsize = 14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9-lAfLKPnHn"
   },
   "source": [
    "Pretty normal distribution, since initially the users are asked to rate at least 20 books (to prevent the cold start) there are no users with less than 20 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vDdBOW_Hu0TC"
   },
   "outputs": [],
   "source": [
    "#Since I don't need the df anymore let's delete it.\n",
    "del rat_pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AmLvVvo5u1kE"
   },
   "outputs": [],
   "source": [
    "rat_pm = ratings_df.groupby(\"book_id\")[\"rating\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "colab_type": "code",
    "id": "QxdicUPaScAH",
    "outputId": "d53bf601-0d4f-472b-8403-b738bafcc766"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAJmCAYAAACwk3pMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = [14,10])\n",
    "plt.hist(rat_pm, bins = 300, color = \"sandybrown\")\n",
    "\n",
    "plt.grid(axis=\"y\", alpha=0.75)\n",
    "plt.xlabel(\"Ratings per book\" , fontsize=14)\n",
    "plt.ylabel(\"Number of books\" , fontsize=14)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.ylabel(\"Number of books\" , fontsize = 14)\n",
    "plt.title(\"Rating Distribution of Goodreads Books\" , fontsize = 14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_NyXyLc_MWos"
   },
   "source": [
    "We can see that the majority of the books don't have a lot of ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ubiYe5BwUPNI",
    "outputId": "81776b24-9fa1-496e-dd4f-285757255851"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22806"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since I'm curios to know which is the book with the most reviews :))\n",
    "ratings_df.groupby(\"book_id\")[\"rating\"].count().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "3bmy24nLXgSG",
    "outputId": "57a57c9b-80cf-43be-a73d-f2cd111fe1be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_id\n",
       "1    22806\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat_pm[ratings_df.groupby(\"book_id\")[\"rating\"].count() == 22806]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "TEmoqOqyaulK",
    "outputId": "6240cfd1-ce52-4dfb-cd97-0418ad72754c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The Hunger Games (The Hunger Games, #1)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df.title[books_df[\"book_id\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCCe-zGFbPmP"
   },
   "outputs": [],
   "source": [
    "#Since I don't need rat_pu anymore I'm going to delete it.\n",
    "del rat_pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dof-n1Lq_Sf8"
   },
   "source": [
    "##2. Deep Learninig Recommendation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YoupH5TTC7mo"
   },
   "outputs": [],
   "source": [
    "#So let's shuffle the rows and then split the dataset to train and test datasets.\n",
    "ratings_df = ratings_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#Testing size can be 100 k (around 1.6% of the data)\n",
    "n = 100000\n",
    "\n",
    "#And create out test/train split.\n",
    "test_df = ratings_df[:n]\n",
    "train_df = ratings_df[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xze8gv0DADJ8"
   },
   "outputs": [],
   "source": [
    "#Now let's create user_id and book_id mapping:\n",
    "user_id_m = {id:i for i, id in enumerate(train_df[\"user_id\"].unique())}\n",
    "book_id_m = {id: i for i, id in enumerate(train_df[\"book_id\"].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwtAJACNguWz"
   },
   "outputs": [],
   "source": [
    "#Apply this mapping to the train and test datasets.\n",
    "train_df_m_u = train_df[\"user_id\"].map(user_id_m)\n",
    "train_df_m_b = train_df[\"book_id\"].map(book_id_m)\n",
    "\n",
    "test_df_m_u = test_df[\"user_id\"].map(user_id_m)\n",
    "test_df_m_b = test_df[\"book_id\"].map(book_id_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "4gWopXmlhfn0",
    "outputId": "19aac3df-297f-4b0a-c2fd-9ea0556cb3ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53424\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "#Set the lenght of users/books and just check what we did.\n",
    "users = len(user_id_m)\n",
    "books = len(book_id_m)\n",
    "print(users)\n",
    "print(books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wqy8p3lUzzps"
   },
   "source": [
    "Since we will have two separate input layers, embeddings etc, seems more logical to use \"Model\" in stead of sequential, as I don't see any logic the input of users to go into the next layer (input of books). But we're gonna concatenate the vectors for those two. With \"Model\" we can tell from which layer the current layer should take it's input. So let's see this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "llCIec-3iwhV"
   },
   "outputs": [],
   "source": [
    "#Set the embedding size.\n",
    "embedding_size = 10\n",
    "\n",
    "#We should start with setting input layers\n",
    "user_id_input = Input(shape = [1], name = \"user\")\n",
    "book_id_input = Input(shape = [1], name = \"book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ylvbPFvUiz4O"
   },
   "outputs": [],
   "source": [
    "#Then we can proceed with user and book embeddings as shown below:\n",
    "user_embedding = Embedding(input_dim = users,\n",
    "                           output_dim = embedding_size,\n",
    "                           input_length = 1, \n",
    "                           name = \"user_embedding\")(user_id_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zkdi9T8kz07L"
   },
   "outputs": [],
   "source": [
    "book_embedding = Embedding(input_dim = books,\n",
    "                           output_dim = embedding_size,\n",
    "                           input_length = 1,\n",
    "                           name = \"book_embedding\")(book_id_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Mm1kRQimOlu"
   },
   "outputs": [],
   "source": [
    "#Then reshape the user and book vectors\n",
    "user_vector = Reshape([embedding_size])(user_embedding)\n",
    "book_vector = Reshape([embedding_size])(book_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EIFzh6iB3Rej"
   },
   "outputs": [],
   "source": [
    "#And concatenate those, so that we can feed it to dense layers\n",
    "concatt = Concatenate()([user_vector, book_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfInCZb_3O1f"
   },
   "outputs": [],
   "source": [
    "#Setting up the dense layers and the outpu\n",
    "dense1 = Dense(128, activation = \"relu\")(concatt)\n",
    "#dense2 = Dense(128)(dense1)\n",
    "#dense3 = Dense(128)(dense2)\n",
    "dense4 = Dense(256, activation = \"relu\")(dense1)\n",
    "out = Dense(1)(dense4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1qc6AIOAoRl"
   },
   "outputs": [],
   "source": [
    "#Setting up two callbacks - one for the tensorboard and one for saving the model (model checkpoint)\n",
    "\n",
    "log_dir=\"logs/profile/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback saving only the best model which can be loaded later eventually\n",
    "cpt_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only = True, \n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "Lb82Rn6Z4cSO",
    "outputId": "7585be34-a4d7-4828-b7bc-0caf6d3e376b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "book (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 10)        534240      user[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "book_embedding (Embedding)      (None, 1, 10)        100000      book[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 10)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10)           0           book_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 20)           0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          2688        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          33024       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 670,209\n",
      "Trainable params: 670,209\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lrnng_rate = 1e-3\n",
    "epchs = 10\n",
    "btch_size = 128\n",
    "\n",
    "model = Model(inputs = [user_id_input, book_id_input], outputs = out)\n",
    "\n",
    "model.compile(loss = \"mse\", optimizer = Adam(lrnng_rate))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "colab_type": "code",
    "id": "fnPSxSb3mWXL",
    "outputId": "e2e2d5e9-2c17-4fae-96e7-87800d0cbbef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5288831 samples, validate on 587648 samples\n",
      "Epoch 1/10\n",
      "    128/5288831 [..............................] - ETA: 31:16:16 - loss: 16.1776WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.138336). Check your callbacks.\n",
      "5288448/5288831 [============================>.] - ETA: 0s - loss: 0.7727\n",
      "Epoch 00001: val_loss improved from inf to 0.73097, saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: training_1/cp.ckpt/assets\n",
      "5288831/5288831 [==============================] - 345s 65us/sample - loss: 0.7727 - val_loss: 0.7310\n",
      "Epoch 2/10\n",
      "5288576/5288831 [============================>.] - ETA: 0s - loss: 0.7045\n",
      "Epoch 00002: val_loss improved from 0.73097 to 0.70047, saving model to training_1/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training_1/cp.ckpt/assets\n",
      "5288831/5288831 [==============================] - 347s 66us/sample - loss: 0.7045 - val_loss: 0.7005\n",
      "Epoch 3/10\n",
      "5288320/5288831 [============================>.] - ETA: 0s - loss: 0.6697\n",
      "Epoch 00003: val_loss improved from 0.70047 to 0.68680, saving model to training_1/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training_1/cp.ckpt/assets\n",
      "5288831/5288831 [==============================] - 350s 66us/sample - loss: 0.6697 - val_loss: 0.6868\n",
      "Epoch 4/10\n",
      "5288704/5288831 [============================>.] - ETA: 0s - loss: 0.6477\n",
      "Epoch 00004: val_loss improved from 0.68680 to 0.68135, saving model to training_1/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training_1/cp.ckpt/assets\n",
      "5288831/5288831 [==============================] - 351s 66us/sample - loss: 0.6477 - val_loss: 0.6814\n",
      "Epoch 5/10\n",
      "5288064/5288831 [============================>.] - ETA: 0s - loss: 0.6322\n",
      "Epoch 00005: val_loss improved from 0.68135 to 0.67843, saving model to training_1/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training_1/cp.ckpt/assets\n",
      "5288831/5288831 [==============================] - 343s 65us/sample - loss: 0.6322 - val_loss: 0.6784\n",
      "Epoch 6/10\n",
      "5288704/5288831 [============================>.] - ETA: 0s - loss: 0.6202\n",
      "Epoch 00006: val_loss did not improve from 0.67843\n",
      "5288831/5288831 [==============================] - 342s 65us/sample - loss: 0.6202 - val_loss: 0.6787\n",
      "Epoch 7/10\n",
      "5288704/5288831 [============================>.] - ETA: 0s - loss: 0.6104\n",
      "Epoch 00007: val_loss did not improve from 0.67843\n",
      "5288831/5288831 [==============================] - 347s 66us/sample - loss: 0.6104 - val_loss: 0.6813\n",
      "Epoch 8/10\n",
      "5288192/5288831 [============================>.] - ETA: 0s - loss: 0.6023\n",
      "Epoch 00008: val_loss did not improve from 0.67843\n",
      "5288831/5288831 [==============================] - 348s 66us/sample - loss: 0.6023 - val_loss: 0.6797\n",
      "Epoch 9/10\n",
      "5288192/5288831 [============================>.] - ETA: 0s - loss: 0.5956\n",
      "Epoch 00009: val_loss did not improve from 0.67843\n",
      "5288831/5288831 [==============================] - 348s 66us/sample - loss: 0.5956 - val_loss: 0.6834\n",
      "Epoch 10/10\n",
      "4180480/5288831 [======================>.......] - ETA: 1:10 - loss: 0.5870Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "#model.fit([train_df_m_u, train_df_m_b],\n",
    "#          train_df[\"rating\"],\n",
    "#          batch_size = btch_size, \n",
    "#          epochs = epchs,\n",
    "#          validation_split = 0.1,\n",
    "#          shuffle = True,\n",
    "#          callbacks = [tensorboard_callback, cpt_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "colab_type": "code",
    "id": "rgzc96Hc_bzw",
    "outputId": "c1618a9d-0458-47dd-853d-06d85ddd36b6"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "  (async () => {\n",
       "      const url = await google.colab.kernel.proxyPort(6006, {\"cache\": true});\n",
       "      const iframe = document.createElement('iframe');\n",
       "      iframe.src = url;\n",
       "      iframe.setAttribute('width', '100%');\n",
       "      iframe.setAttribute('height', '800');\n",
       "      iframe.setAttribute('frameborder', 0);\n",
       "      document.body.appendChild(iframe);\n",
       "  })();\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#I was pleasantly surprised when I saw there's the option to run tensorboard in google colab.... well not for long.\n",
    "#Since I've tried several times to run it and every single time received an error below I'm just leaving it - I tried. ;(\n",
    "#%tensorboard --logdir logs/profile/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "L41p-2UE93JA",
    "outputId": "06fa3ff4-853f-4d24-c844-43098fb12782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing Result With Keras Deep Learning: 0.6798 MSE\n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict([test_df_m_u, test_df_m_b])\n",
    "#y_true = test_df[\"rating\"].values\n",
    "\n",
    "#mse = mean_squared_error(y_pred=y_pred, y_true=y_true)\n",
    "#print(\"\\n\\nTesting Result With Keras Deep Learning: {:.4f} MSE\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "XHFksJptnm_Q",
    "outputId": "d59dc552-4402-4751-bd9f-d6c2ff22516d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/profile/\n",
      "logs/profile/20200214-032655/\n",
      "logs/profile/20200214-032655/validation/\n",
      "logs/profile/20200214-032655/validation/events.out.tfevents.1581651158.cb45734a9039.141.258307.v2\n",
      "logs/profile/20200214-032655/train/\n",
      "logs/profile/20200214-032655/train/events.out.tfevents.1581650818.cb45734a9039.profile-empty\n",
      "logs/profile/20200214-032655/train/plugins/\n",
      "logs/profile/20200214-032655/train/plugins/profile/\n",
      "logs/profile/20200214-032655/train/plugins/profile/2020-02-14_03-26-58/\n",
      "logs/profile/20200214-032655/train/plugins/profile/2020-02-14_03-26-58/local.trace\n",
      "logs/profile/20200214-032655/train/events.out.tfevents.1581650815.cb45734a9039.141.278.v2\n"
     ]
    }
   ],
   "source": [
    "#Found alternative for the tensorboard so I'm going to work around this.\n",
    "#https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_profiling_keras.ipynb#scrollTo=TZOf_K4L-Nkv\n",
    "#!tar -zcvf logs.tar.gz logs/profile/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/1st_training.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-UY8UQAltVcC"
   },
   "source": [
    "Orange is train, blue is validation losses respectively. Really no point to run after epoch 7 because we start overfitting and our validation loss increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z4XSmcj5Elto"
   },
   "source": [
    "So below I'm going to make some minor modifications and train the model again. Not going to put the text above each code as this has been already mentioned in the first example. Might explore the option to put a function for the repetitive stuff, but for now I find it more easier for debugging/tracking purposes to have everything outlined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JUw7Eokz0Rj_"
   },
   "outputs": [],
   "source": [
    "dense1 = Dense(128, activation = \"relu\")(concatt)\n",
    "#dense2 = Dropout(drpt_rate)(dense1)\n",
    "dense3 = Dense(256, activation = \"relu\")(dense1)\n",
    "#dense4 = Dropout(drpt_rate)(dense3)\n",
    "\n",
    "out = Dense(1)(dense3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1UQE6nh-0Kz"
   },
   "outputs": [],
   "source": [
    "log_dir=\"logs/profile/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "checkpoint_path = \"training_2/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback saving only the best model which can be loaded later eventually\n",
    "cpt_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only = True, \n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "gfIK1bvz-Avg",
    "outputId": "6caddd1f-0153-4df9-d9b1-d79f85d4db0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "book (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 10)        534240      user[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "book_embedding (Embedding)      (None, 1, 10)        100000      book[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 10)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10)           0           book_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 20)           0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          2688        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          33024       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            257         dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 670,209\n",
      "Trainable params: 670,209\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#So let's change the learning rate and see what the impact of this will be.\n",
    "lrnng_rate = 1e-4\n",
    "epchs = 7\n",
    "btch_size = 128\n",
    "\n",
    "model = Model(inputs = [user_id_input, book_id_input], outputs = out)\n",
    "\n",
    "model.compile(loss = \"mse\", optimizer = Adam(lrnng_rate))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 760
    },
    "colab_type": "code",
    "id": "5QsjDAWu-Aq1",
    "outputId": "1024f5f0-4d3d-420c-a3d0-baf1ffea126d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5288831 samples, validate on 587648 samples\n",
      "Epoch 1/7\n",
      "5288576/5288831 [============================>.] - ETA: 0s - loss: 0.6391\n",
      "Epoch 00001: val_loss improved from inf to 0.68660, saving model to training_2/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training_2/cp.ckpt/assets\n",
      "5288831/5288831 [==============================] - 341s 64us/sample - loss: 0.6391 - val_loss: 0.6866\n",
      "Epoch 2/7\n",
      "5288576/5288831 [============================>.] - ETA: 0s - loss: 0.5850\n",
      "Epoch 00002: val_loss did not improve from 0.68660\n",
      "5288831/5288831 [==============================] - 349s 66us/sample - loss: 0.5850 - val_loss: 0.6902\n",
      "Epoch 3/7\n",
      "5288320/5288831 [============================>.] - ETA: 0s - loss: 0.5766\n",
      "Epoch 00003: val_loss did not improve from 0.68660\n",
      "5288831/5288831 [==============================] - 341s 64us/sample - loss: 0.5766 - val_loss: 0.6885\n",
      "Epoch 4/7\n",
      "5288576/5288831 [============================>.] - ETA: 0s - loss: 0.5716\n",
      "Epoch 00004: val_loss did not improve from 0.68660\n",
      "5288831/5288831 [==============================] - 336s 64us/sample - loss: 0.5716 - val_loss: 0.6933\n",
      "Epoch 5/7\n",
      "4356352/5288831 [=======================>......] - ETA: 59s - loss: 0.5675WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4356352/5288831 [=======================>......] - ETA: 59s - loss: 0.5675"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-343b693a2a4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           callbacks = [tensorboard_callback, cpt_callback])\n\u001b[0m",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             batch_end=step * batch_size + current_batch_size)\n\u001b[1;32m    180\u001b[0m       \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[0;34m(self, step, mode, size)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_exhausted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m           self.callbacks._call_batch_hook(\n\u001b[0;32m--> 788\u001b[0;31m               mode, 'end', step, batch_logs)\n\u001b[0m\u001b[1;32m    789\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m       \u001b[0mbatch_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m       \u001b[0mbatch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1689\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'batch_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_increment_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_run_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_increment_step\u001b[0;34m(self, writer_name)\u001b[0m\n\u001b[1;32m   1658\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_batches_seen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwriter_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1660\u001b[0;31m       \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1661\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_batches_seen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwriter_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(self, delta, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    784\u001b[0m       assign_add_op = gen_resource_variable_ops.assign_add_variable_op(\n\u001b[1;32m    785\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    787\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_add_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_add_variable_op\u001b[0;34m(resource, value, name)\u001b[0m\n\u001b[1;32m     42\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m     43\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AssignAddVariableOp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         tld.op_callbacks, resource, value)\n\u001b[0m\u001b[1;32m     45\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model.fit([train_df_m_u, train_df_m_b],\n",
    "#          train_df[\"rating\"],\n",
    "#          batch_size = btch_size,\n",
    "#          epochs = epchs,\n",
    "#          validation_split = 0.1,\n",
    "#          shuffle = True,\n",
    "#          callbacks = [tensorboard_callback, cpt_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zzUYS5vOHfwp"
   },
   "source": [
    "Stopeed it intentionally. Really no point in running more epochs as I can see that the results are not better and the validation loss increases or stays higher that the 1st training (and the lowest epoch for the current training achieve in epoch 1 of MSE 0.6866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "C62GW-z2_rs0",
    "outputId": "2a5c903e-8189-49b3-8c0c-9f48aa81c47c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/profile/\n",
      "logs/profile/20200213-184316/\n",
      "logs/profile/20200213-184316/validation/\n",
      "logs/profile/20200213-184316/validation/events.out.tfevents.1581619694.14b4085c7157.140.1553580.v2\n",
      "logs/profile/20200213-184316/train/\n",
      "logs/profile/20200213-184316/train/events.out.tfevents.1581619417.14b4085c7157.profile-empty\n",
      "logs/profile/20200213-184316/train/events.out.tfevents.1581619416.14b4085c7157.140.1295453.v2\n",
      "logs/profile/20200213-184316/train/plugins/\n",
      "logs/profile/20200213-184316/train/plugins/profile/\n",
      "logs/profile/20200213-184316/train/plugins/profile/2020-02-13_18-43-37/\n",
      "logs/profile/20200213-184316/train/plugins/profile/2020-02-13_18-43-37/local.trace\n",
      "logs/profile/.ipynb_checkpoints/\n"
     ]
    }
   ],
   "source": [
    "# Skipping also this part\n",
    "#!tar -zcvf logs.tar.gz logs/profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "bF72twC4-AoR",
    "outputId": "b489fe28-528e-4238-c2e6-6f8217d139a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing Result With Keras Deep Learning: 0.6899 MSE\n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict([test_df_m_u, test_df_m_b])\n",
    "#y_true = test_df[\"rating\"].values\n",
    "\n",
    "#mse = mean_squared_error(y_pred=y_pred, y_true=y_true)\n",
    "#print(\"\\n\\nTesting Result With Keras Deep Learning: {:.4f} MSE\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwACypNm94mA"
   },
   "source": [
    "The MSE error on the test set is higher as expected after seeing the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "afZp9dRx-Amb",
    "outputId": "9e1b411d-e7a8-47bb-bce3-71280570c8d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 2).\n",
       "Contents of stderr:\n",
       "usage: tensorboard [-h] [--helpfull] {serve,dev} ...\n",
       "tensorboard: error: invalid choice: '—' (choose from 'serve', 'dev')"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%tensorboard — logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZdUrE9HWF-Ow"
   },
   "source": [
    "Now I'm going to add new layer and see if the MSE will improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6jL1nU9-Ajp"
   },
   "outputs": [],
   "source": [
    "#Setting up the layers:\n",
    "\n",
    "dense1 = Dense(64, activation = \"relu\")(concatt)\n",
    "dense2 = Dense(128, activation = \"relu\")(dense1)\n",
    "dense3 = Dense(256, activation = \"relu\")(dense2)\n",
    "#dense4 = Dropout(drpt_rate)(dense3)\n",
    "\n",
    "out = Dense(1)(dense3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "loI_JVw--Aev"
   },
   "outputs": [],
   "source": [
    "#Setting up the callbacks:\n",
    "\n",
    "log_dir=\"logs/profile/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "checkpoint_path = \"training_3/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback saving only the best model which can be loaded later eventually\n",
    "cpt_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only = True, \n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "HnEy1rLm-AO-",
    "outputId": "740fae77-314e-45ac-c232-33554117759f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "book (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 10)        534240      user[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "book_embedding (Embedding)      (None, 1, 10)        100000      book[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 10)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10)           0           book_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 20)           0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           1344        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          8320        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          33024       dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            257         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 677,185\n",
      "Trainable params: 677,185\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lrnng_rate = 1e-3\n",
    "epchs = 7\n",
    "btch_size = 128\n",
    "\n",
    "model = Model(inputs = [user_id_input, book_id_input], outputs = out)\n",
    "\n",
    "model.compile(loss = \"mse\", optimizer = Adam(lrnng_rate))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "itTLniz_-AYY",
    "outputId": "87226b0d-e26f-4739-c7e3-8f2d4115d42c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5288831 samples, validate on 587648 samples\n",
      "Epoch 1/7\n",
      "5288192/5288831 [============================>.] - ETA: 0s - loss: 0.6150\n",
      "Epoch 00001: val_loss improved from inf to 0.68166, saving model to training_3/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training_3/cp.ckpt/assets\n",
      "5288831/5288831 [==============================] - 352s 67us/sample - loss: 0.6150 - val_loss: 0.6817\n",
      "Epoch 2/7\n",
      "5288704/5288831 [============================>.] - ETA: 0s - loss: 0.5930\n",
      "Epoch 00002: val_loss did not improve from 0.68166\n",
      "5288831/5288831 [==============================] - 352s 67us/sample - loss: 0.5930 - val_loss: 0.6825\n",
      "Epoch 3/7\n",
      "5288576/5288831 [============================>.] - ETA: 0s - loss: 0.5856\n",
      "Epoch 00003: val_loss did not improve from 0.68166\n",
      "5288831/5288831 [==============================] - 345s 65us/sample - loss: 0.5856 - val_loss: 0.6819\n",
      "Epoch 4/7\n",
      "5288448/5288831 [============================>.] - ETA: 0s - loss: 0.5803\n",
      "Epoch 00004: val_loss did not improve from 0.68166\n",
      "5288831/5288831 [==============================] - 353s 67us/sample - loss: 0.5803 - val_loss: 0.6839\n",
      "Epoch 5/7\n",
      "5288192/5288831 [============================>.] - ETA: 0s - loss: 0.5755\n",
      "Epoch 00005: val_loss did not improve from 0.68166\n",
      "5288831/5288831 [==============================] - 345s 65us/sample - loss: 0.5755 - val_loss: 0.6871\n",
      "Epoch 6/7\n",
      "5288448/5288831 [============================>.] - ETA: 0s - loss: 0.5715\n",
      "Epoch 00006: val_loss did not improve from 0.68166\n",
      "5288831/5288831 [==============================] - 344s 65us/sample - loss: 0.5715 - val_loss: 0.6830\n",
      "Epoch 7/7\n",
      "5288576/5288831 [============================>.] - ETA: 0s - loss: 0.5677\n",
      "Epoch 00007: val_loss did not improve from 0.68166\n",
      "5288831/5288831 [==============================] - 345s 65us/sample - loss: 0.5677 - val_loss: 0.6895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa1c5afd9e8>"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit([train_df_m_u, train_df_m_b],\n",
    "#          train_df[\"rating\"],\n",
    "#          batch_size = btch_size, \n",
    "#          epochs = epchs,\n",
    "#          validation_split = 0.1,\n",
    "#          shuffle = True,\n",
    "#          callbacks = [tensorboard_callback, cpt_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "eCLF6mrq-AEa",
    "outputId": "8617c2d0-3fdc-41b7-efdd-efaad47ebc76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing Result With Keras Deep Learning: 0.6873 MSE\n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict([test_df_m_u, test_df_m_b])\n",
    "#y_true = test_df[\"rating\"].values\n",
    "\n",
    "#mse = mean_squared_error(y_pred=y_pred, y_true=y_true)\n",
    "#print(\"\\n\\nTesting Result With Keras Deep Learning: {:.4f} MSE\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "48j876u5DTbW",
    "outputId": "2c7d84b5-9855-492c-bf69-6222bc26ac1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/profile/\n",
      "logs/profile/.ipynb_checkpoints/\n",
      "logs/profile/20200214-052130/\n",
      "logs/profile/20200214-052130/validation/\n",
      "logs/profile/20200214-052130/validation/events.out.tfevents.1581658217.cb45734a9039.141.4077805.v2\n",
      "logs/profile/20200214-052130/train/\n",
      "logs/profile/20200214-052130/train/events.out.tfevents.1581657865.cb45734a9039.141.3819707.v2\n",
      "logs/profile/20200214-052130/train/events.out.tfevents.1581657866.cb45734a9039.profile-empty\n",
      "logs/profile/20200214-052130/train/plugins/\n",
      "logs/profile/20200214-052130/train/plugins/profile/\n",
      "logs/profile/20200214-052130/train/plugins/profile/2020-02-14_05-24-26/\n",
      "logs/profile/20200214-052130/train/plugins/profile/2020-02-14_05-24-26/local.trace\n"
     ]
    }
   ],
   "source": [
    "#!tar -zcvf logs.tar.gz logs/profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFZu1gN7XITC"
   },
   "source": [
    "![title](img/3rd_training.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBqpcQcBWfFk"
   },
   "source": [
    "So more deepener network didn't improve the MSE metric. Let's decrease the learninig rate then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dKUEiJx_VHYa"
   },
   "outputs": [],
   "source": [
    "dense1 = Dense(128, activation = \"relu\")(concatt)\n",
    "#dense2 = Dropout(drpt_rate)(dense1)\n",
    "dense3 = Dense(256, activation = \"relu\")(dense1)\n",
    "#dense4 = Dropout(drpt_rate)(dense3)\n",
    "\n",
    "out = Dense(1)(dense3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8AzXeY_LW2Hp"
   },
   "outputs": [],
   "source": [
    "log_dir=\"logs/profile/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "checkpoint_path = \"training_4/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback saving only the best model which can be loaded later eventually\n",
    "cpt_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only = True, \n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "jcSIqruNW-ki",
    "outputId": "c1c7dfe8-6b21-4112-caab-cdb703d0284e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "book (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 10)        534240      user[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "book_embedding (Embedding)      (None, 1, 10)        100000      book[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 10)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10)           0           book_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 20)           0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 128)          2688        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 256)          33024       dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            257         dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 670,209\n",
      "Trainable params: 670,209\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#So let's change the learning rate and see what the impact of this will be.\n",
    "lrnng_rate = 1e-2\n",
    "epchs = 7\n",
    "btch_size = 128\n",
    "\n",
    "model = Model(inputs = [user_id_input, book_id_input], outputs = out)\n",
    "\n",
    "model.compile(loss = \"mse\", optimizer = Adam(lrnng_rate))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "colab_type": "code",
    "id": "ANbqHy3-XFX6",
    "outputId": "1038ee69-feaf-4784-b0f4-02120bb277a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5288831 samples, validate on 587648 samples\n",
      "Epoch 1/7\n",
      "5288320/5288831 [============================>.] - ETA: 0s - loss: 0.6949\n",
      "Epoch 00001: val_loss improved from inf to 0.69751, saving model to training_4/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training_4/cp.ckpt/assets\n",
      "5288831/5288831 [==============================] - 340s 64us/sample - loss: 0.6949 - val_loss: 0.6975\n",
      "Epoch 2/7\n",
      "5288320/5288831 [============================>.] - ETA: 0s - loss: 0.6573\n",
      "Epoch 00002: val_loss improved from 0.69751 to 0.69724, saving model to training_4/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training_4/cp.ckpt/assets\n",
      "5288831/5288831 [==============================] - 344s 65us/sample - loss: 0.6574 - val_loss: 0.6972\n",
      "Epoch 3/7\n",
      "5288064/5288831 [============================>.] - ETA: 0s - loss: 0.6374\n",
      "Epoch 00003: val_loss improved from 0.69724 to 0.68504, saving model to training_4/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training_4/cp.ckpt/assets\n",
      "5288831/5288831 [==============================] - 342s 65us/sample - loss: 0.6374 - val_loss: 0.6850\n",
      "Epoch 4/7\n",
      "5288576/5288831 [============================>.] - ETA: 0s - loss: 0.6247\n",
      "Epoch 00004: val_loss did not improve from 0.68504\n",
      "5288831/5288831 [==============================] - 345s 65us/sample - loss: 0.6247 - val_loss: 0.6881\n",
      "Epoch 5/7\n",
      "5288448/5288831 [============================>.] - ETA: 0s - loss: 0.6156\n",
      "Epoch 00005: val_loss did not improve from 0.68504\n",
      "5288831/5288831 [==============================] - 359s 68us/sample - loss: 0.6156 - val_loss: 0.6906\n",
      "Epoch 6/7\n",
      "5288704/5288831 [============================>.] - ETA: 0s - loss: 0.6085\n",
      "Epoch 00006: val_loss did not improve from 0.68504\n",
      "5288831/5288831 [==============================] - 339s 64us/sample - loss: 0.6085 - val_loss: 0.6856\n",
      "Epoch 7/7\n",
      "5288064/5288831 [============================>.] - ETA: 0s - loss: 0.6032\n",
      "Epoch 00007: val_loss did not improve from 0.68504\n",
      "5288831/5288831 [==============================] - 339s 64us/sample - loss: 0.6032 - val_loss: 0.6904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa167fc4fd0>"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit([train_df_m_u, train_df_m_b],\n",
    "#          train_df[\"rating\"],\n",
    "#          batch_size = btch_size, \n",
    "#          epochs = epchs,\n",
    "#          validation_split = 0.1,\n",
    "#          shuffle = True,\n",
    "#          callbacks = [tensorboard_callback, cpt_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "5JdcUbDOXhfj",
    "outputId": "d65f9d61-184c-4c97-e757-ab0de11ae176"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing Result With Keras Deep Learning: 0.6876 MSE\n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict([test_df_m_u, test_df_m_b])\n",
    "#y_true = test_df[\"rating\"].values\n",
    "\n",
    "#mse = mean_squared_error(y_pred=y_pred, y_true=y_true)\n",
    "#print(\"\\n\\nTesting Result With Keras Deep Learning: {:.4f} MSE\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "WPfimdIdg1h2",
    "outputId": "334d3c2f-2cf9-41a2-c521-5ff00de5b4ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/profile/\n",
      "logs/profile/.ipynb_checkpoints/\n",
      "logs/profile/20200214-062339/\n",
      "logs/profile/20200214-062339/validation/\n",
      "logs/profile/20200214-062339/validation/events.out.tfevents.1581661765.cb45734a9039.141.5883762.v2\n",
      "logs/profile/20200214-062339/train/\n",
      "logs/profile/20200214-062339/train/plugins/\n",
      "logs/profile/20200214-062339/train/plugins/profile/\n",
      "logs/profile/20200214-062339/train/plugins/profile/2020-02-14_06-23-47/\n",
      "logs/profile/20200214-062339/train/plugins/profile/2020-02-14_06-23-47/local.trace\n",
      "logs/profile/20200214-062339/train/events.out.tfevents.1581661427.cb45734a9039.profile-empty\n",
      "logs/profile/20200214-062339/train/events.out.tfevents.1581661426.cb45734a9039.141.5625733.v2\n"
     ]
    }
   ],
   "source": [
    "#For the last time I'm going to download the logs and view them on tensorboard\n",
    "#!tar -zcvf logs.tar.gz logs/profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WiHD_hTKj_Sc"
   },
   "source": [
    "![title](img/4th_training.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXXaSHFpj9Wu"
   },
   "source": [
    "Best model checkpoints attached in the \"Logs and Ckpts\" folder together with this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oVl6TAXZfmdF"
   },
   "source": [
    "#4. Conclusoin\n",
    "\n",
    "It turns out that the deep learning optimization is a lot more harder than the simpler grid_search. Couldn't decrease the mse loss more than the initial training. Though I did try a few combinations(out of this notebook) before deciding on the initial one. Next steps would be to work with a smaller sample, overfit it a bit and then regularize it. Another thing which I think about is to oversample the instances with low ratings as those were a really small part of the whole dataset (around 8%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "book_recommender.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
